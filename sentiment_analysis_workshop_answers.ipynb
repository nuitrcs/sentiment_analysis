{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis of Text Data\n",
        "\n",
        "#### Introduction to sentiment analysis\n",
        "\n",
        "Sentiment analysis consists of assigning the label \"positive\", \"negative\" or \"neutral\" to a document based on its overall polarity. For example, this sentence would have a negative sentiment: \"Climate change is terrible. I am really worried.\"\n",
        "\n",
        "While it seems simple, sentiment analysis can be quite complex. For instance, sarcasm is hard to identify. Notice how minor changes to the above sentence would lead a human to understand it differently, while a computer would have a harder time: \"Sure, sure, I get it, climate change is terrible. I am really worried...\"\n",
        "\n",
        "Sentiment analysis is related to other methods for natural language processing. For example, sentiment analysis is related to the task of assigning a topic to a document (topic modeling). Similarly, sentiment analysis is related to stance detection, but is not exactly the same. Sentiment analysis focuses on the overall tone of a document, while stance detection focuses on the tone of a document regarding a specific entity.\n",
        "\n",
        "#### Sentiment analysis for research\n",
        "\n",
        "Sentiment analysis can be useful for research with text data, for example, to analyze social media posts, open-ended survey responses, news, and political speeches.\n",
        "\n",
        "This notebook covers different approaches to sentiment analysis focusing on research applications. Many methods and datasets for sentiment analysis are tailored for industry applications and may not work well off-the-shelf in a research context.\n",
        "\n",
        "#### What to expect from this notebook\n",
        "\n",
        "This notebook focuses on conveying the idea that there are different approaches to sentiment analysis, give you a sense of what they are and when to consider them, and show you possible basic implementations. However, **each of the approaches has many more details to consider**, which is outside of the scope of this notebook. You are always welcome to [submit a consult request with Research Computing and Data Services](https://app.smartsheet.com/b/form/2f2ec327e6164f83b588b7bbe2e2b56f) if you need help with the data-related aspects of your research.\n",
        "\n",
        "## Import libraries"
      ],
      "metadata": {
        "id": "-2TPLCMoVsVU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIJOPBwfVhZr"
      },
      "outputs": [],
      "source": [
        "# To use dataframes\n",
        "import pandas as pd\n",
        "\n",
        "# To use the VADER dictionary and NLTK's tokenizer\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('punkt_tab')\n",
        "from nltk import tokenize\n",
        "\n",
        "# To use a pre-trained model from Hugging Face\n",
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# To use structured output\n",
        "from pydantic import BaseModel\n",
        "from typing import Literal\n",
        "\n",
        "# To use OpenAI API's key in Google Colab\n",
        "# https://drlee.io/how-to-use-secrets-in-google-colab-for-api-key-protection-a-guide-for-openai-huggingface-and-c1ec9e1277e0\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# To use OpenAI's API\n",
        "from openai import OpenAI\n",
        "\n",
        "# To train a model from scratch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read data\n",
        "\n",
        "The data are available in [this GitHub repo](https://github.com/emiliolehoucq/trainings/tree/main/data).\n",
        "- `tweets.csv` is a sample of 5000 rows from [this replication package](https://doi.org/10.7910/DVN/SFQTJZ) for [this article](https://doi.org/10.1073/pnas.2210988119). The original dataset consisted of 18,896,054 publicly available tweets from 1 January 2019 to 31 December 2021 that mention climate change in the text of the post.\n",
        "- `nyt.csv` is a sample of 5000 rows from [this replication package](https://doi.org/10.7910/DVN/FVRZYU) for [this article](https://doi.org/10.1111/ajps.12702). The original dataset consisted of 9,341 *New York Times* articles that contain phrases related to economic mobility (i.e., \"upward mobility\", \"land of opportunity\", \"self-made success\")."
      ],
      "metadata": {
        "id": "6WwxazpAV3Y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_nyt = pd.read_csv(\"https://raw.githubusercontent.com/emiliolehoucq/trainings/refs/heads/main/data/nyt.csv\")\n",
        "df_tweets = pd.read_csv(\"https://raw.githubusercontent.com/emiliolehoucq/trainings/refs/heads/main/data/tweets.csv\")\n",
        "\n",
        "# Lowercase column names in df_tweets\n",
        "df_tweets.columns = df_tweets.columns.str.lower()"
      ],
      "metadata": {
        "id": "p6wFEBgYV20C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explore data"
      ],
      "metadata": {
        "id": "rRjqOIZGV5S1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_nyt.shape"
      ],
      "metadata": {
        "id": "6-VezFGD3OsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_nyt.head(1)"
      ],
      "metadata": {
        "id": "ErV-ROILw8Ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll focus on the `text` column."
      ],
      "metadata": {
        "id": "8Lr3JjaR5HO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to print \"=\" to make the output easier to read\n",
        "def print_format():\n",
        "  print(\"=\" * 100)\n",
        "  print(\"=\" * 100)\n",
        "  print(\"=\" * 100)\n",
        "  print(\"=\" * 100)\n",
        "  print(\"=\" * 100)\n",
        "\n",
        "for i, row in df_nyt.sample(10, random_state=51425).iterrows():\n",
        "  print(row['text'])\n",
        "  print_format()"
      ],
      "metadata": {
        "id": "qdw0XGGqd2WC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that the text has been processed to some degree.\n",
        "\n",
        "You can learn more about text processing in this [workshop on parsing text with NLTK](https://github.com/nuitrcs/parsing_text_nltk)."
      ],
      "metadata": {
        "id": "JhDLelxxejS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tweets.shape"
      ],
      "metadata": {
        "id": "20cOYMOE3Rh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tweets.head(1)"
      ],
      "metadata": {
        "id": "B4psbTp-1dGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll focus on the `text` column."
      ],
      "metadata": {
        "id": "9UUZO1lFeIdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, row in df_tweets.sample(10, random_state=51425).iterrows():\n",
        "  print(row['text'])\n",
        "  print_format()"
      ],
      "metadata": {
        "id": "jq-T4_faeI1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that the text has been processed to some degree.\n",
        "\n",
        "## Overview of approaches to sentiment analysis\n",
        "\n",
        "This section provides an overview of different approaches to sentiment analysis, their pros and cons, and some possible use cases. **Keep in mind that you can potentially use approaches in combination.**\n",
        "\n",
        "#### Warning on evaluation\n",
        "\n",
        "Given data and time constraints, this notebook does not delve deep into evaluation. **However, regardless of which approach you use for a particular project, it is important to evaluate its performance. Typically, the evaluation requires manually labelling of a sample (which could be a simple random sample, a stratified sample) and comparing against the computational method using [metrics such as accuracy, recall, and precision](https://developers.google.com/machine-learning/crash-course/classification/accuracy-precision-recall). Also, as you (probably iteratively) decide on and implement a particular approach, it is important to understand your corpus well, keep in mind your research focus, and quickly see how a given approach seems to be performing. Do not leave evaluation just until the end. Finally, you may want to try different approaches and compare their performance.**\n",
        "\n",
        "### Dictionary or lexicon\n",
        "\n",
        "Definition: assign sentiment based on the prevalence of positive vs. negative words contained in a dictionary or lexicon.<br>\n",
        "Pros: transparent, easy to implement, doesn't require labeled data.<br>\n",
        "Cons: doesn't account for how words are used (ambiguity, context, domain-specific connotations, sarcasm, negation), may not identify relevant words or tokens, requires tokenization.<br>\n",
        "Use cases: baseline to compare other approaches, small dataset, too expensive to label data, secondary analysis.<br>\n",
        "\n",
        "There are various common dictionaries used in sentiment analysis. They are designed for different use cases and can vary in size and complexity.\n",
        "\n",
        "For example, the [VADER](https://doi.org/10.1609/icwsm.v8i1.14550) lexicon is designed for short, informal documents such as social media posts or open-ended survey responses. VADER uses a crowdsourced vocabulary of over 7,500 terms including slang, emojis, and unconventional spelling. Further, VADER uses an algorithmic approach that doesn't rely solely on word counts, but follow algorithmic rules. For instance, exclamation marks and all caps serve as multipliers and intensifying adjectives and adverbs can also increase the sentiment of the term that they modify. Finally, VADER evaluates terms in local-window contexts of three words to capture negations and flip sentiment polarity accordingly.\n",
        "\n",
        "Another example is [Lexicoder Sentiment Dictionary (LSD)](https://doi.org/10.1080/10584609.2012.671234), which is designed to measure sentiment in political texts by including terms specific to political discourse that do not exist in other lexicons.\n",
        "\n",
        "For this notebook, we're going to use the [VADER dictionary](https://www.nltk.org/api/nltk.sentiment.vader.html#module-nltk.sentiment.vader) from the [NLTK](https://www.nltk.org/) library. ([More information here](https://www.analyticsvidhya.com/blog/2022/10/sentiment-analysis-using-vader/).)"
      ],
      "metadata": {
        "id": "FiAt-jDqV65e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the sentiment analyzer\n",
        "sia = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "1f5eTysUYNeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "sia.polarity_scores(\"This workshop is amazing! Love it! Great instructor!\")"
      ],
      "metadata": {
        "id": "aqmx2abDapaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that the sentiment analyzer takes full sentences. If your document has more than one sentence, you need to [use a sentence tokenizer](https://www.nltk.org/howto/sentiment.html#vader). In this case, since the tweets have already been processed, we're going to pretend that they are only one sentence."
      ],
      "metadata": {
        "id": "3cYihajHdb3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the sentiment analyzer to the text\n",
        "df_tweets['sentiment_scores'] = df_tweets['text'].apply(sia.polarity_scores)"
      ],
      "metadata": {
        "id": "wJSMNeB1YO1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tweets.columns"
      ],
      "metadata": {
        "id": "gPjdefOPYO4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, row in df_tweets.sample(10, random_state=51425).iterrows():\n",
        "  print(row['text'])\n",
        "  print(row['sentiment_scores'])\n",
        "  print_format()"
      ],
      "metadata": {
        "id": "0XaCIDdaYO7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract compound score\n",
        "# Learn more about the compound score: https://stackoverflow.com/questions/40325980/how-is-the-vader-compound-polarity-score-calculated-in-python-nltk\n",
        "df_tweets['compound'] = df_tweets['sentiment_scores'].apply(lambda x: x['compound'])\n",
        "\n",
        "# Define function to categorize sentiment\n",
        "# Notice that this is a choice you have to make\n",
        "# There are other ways of classifying\n",
        "# You have to think about the \"right\" way for your project\n",
        "def categorize_sentiment(compound_score):\n",
        "    if compound_score >= 0.05:\n",
        "        return 'positive'\n",
        "    elif compound_score <= -0.05:\n",
        "        return 'negative'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n",
        "# Apply categorization\n",
        "df_tweets['sentiment'] = df_tweets['compound'].apply(categorize_sentiment)"
      ],
      "metadata": {
        "id": "uticysJ6YO9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, row in df_tweets.sample(10, random_state=51425).iterrows():\n",
        "  print(row['text'])\n",
        "  print(row['sentiment_scores'])\n",
        "  print(row['sentiment'])\n",
        "  print_format()"
      ],
      "metadata": {
        "id": "6LW3TiA_ZWrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise\n",
        "\n",
        "Apply the approach above to the `df_nyt` dataset."
      ],
      "metadata": {
        "id": "Ktl_XHCE3apf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize each document\n",
        "df_nyt['sentences'] = df_nyt['text'].apply(tokenize.sent_tokenize)"
      ],
      "metadata": {
        "id": "sE4-tfmz3ftn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, row in df_nyt.sample(10, random_state=51425).iterrows():\n",
        "  print(row['text'])\n",
        "  print(row['sentences'])\n",
        "  print_format()"
      ],
      "metadata": {
        "id": "mpn2Rw3zhDtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Subset dataset for speed\n",
        "df_nyt_subset = df_nyt.sample(10, random_state=51425)\n",
        "\n",
        "# Analyze each sentence\n",
        "df_nyt_subset['sentiment_scores'] = df_nyt_subset['sentences'].apply(lambda x: [sia.polarity_scores(sentence) for sentence in x])"
      ],
      "metadata": {
        "id": "7NqVmcHxhYLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, row in df_nyt_subset.sample(10, random_state=51425).iterrows():\n",
        "  print(row['sentences'])\n",
        "  print(row['sentiment_scores'])\n",
        "  print_format()"
      ],
      "metadata": {
        "id": "bh_P7AaihiS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the compound score\n",
        "df_nyt_subset['compound'] = df_nyt_subset['sentiment_scores'].apply(lambda x: [score['compound'] for score in x])"
      ],
      "metadata": {
        "id": "EE5x-BHRhvum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, row in df_nyt_subset.sample(10, random_state=51425).iterrows():\n",
        "  print(row['sentences'])\n",
        "  print(row['compound'])\n",
        "  print_format()"
      ],
      "metadata": {
        "id": "xe1zwAl_hy_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average compound score for each document\n",
        "# Note that this is a choice. There are different options and you have to decide for your project\n",
        "df_nyt_subset['average_compound'] = df_nyt_subset['compound'].apply(lambda x: sum(x) / len(x))"
      ],
      "metadata": {
        "id": "oyIHLkqWh1t6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, row in df_nyt_subset.sample(10, random_state=51425).iterrows():\n",
        "  print(row['sentences'])\n",
        "  print(row['compound'])\n",
        "  print(row['average_compound'])\n",
        "  print_format()"
      ],
      "metadata": {
        "id": "TpXR8Xb4iDMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate sentiment label for each document\n",
        "df_nyt_subset['sentiment'] = df_nyt_subset['average_compound'].apply(categorize_sentiment)"
      ],
      "metadata": {
        "id": "Ux417CvjiGum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, row in df_nyt_subset.sample(10, random_state=51425).iterrows():\n",
        "  print(row['text'])\n",
        "  print(row['sentiment'])"
      ],
      "metadata": {
        "id": "s-ddnnYDiJ8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-trained classifier\n",
        "\n",
        "Definition: using a machine learning model that has already been trained for sentiment analysis.<br>\n",
        "Pros: easy to implement, potentially better than dictionaries.<br>\n",
        "Cons: opaque, requires a pre-trained model appropriate for the task, can be biased.<br>\n",
        "Use cases: many of the same use cases than dictionary-based sentiment analysis--baseline to compare other approaches, small dataset, too expensive to label data, secondary analysis.<br>\n",
        "\n",
        "Hugging Face is a good place to [find pre-trained models](https://huggingface.co/models) and has a [task page](https://huggingface.co/tasks/text-classification) with information about text classification, including sentiment analysis."
      ],
      "metadata": {
        "id": "v07kTVhiWLOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the sentiment analysis pipeline\n",
        "model_name = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model_name)"
      ],
      "metadata": {
        "id": "4BJRedTRWKsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You have to look at the model card for information about the specific model. For example, this is the [model card for `distilbert/distilbert-base-uncased-finetuned-sst-2-english`](https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english)."
      ],
      "metadata": {
        "id": "qKCs6KfDnNXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a subset of the dataset because this can take a bit\n",
        "df_tweets_subset = df_tweets.sample(50, random_state=51425)\n",
        "\n",
        "# Apply the sentiment analysis pipeline to each tweet\n",
        "df_tweets_subset['sentiment'] = df_tweets_subset['text'].apply(lambda x: sentiment_pipeline(x))"
      ],
      "metadata": {
        "id": "K95uyiiyl0fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, row in df_tweets_subset.sample(10, random_state=51425).iterrows():\n",
        "  print(row['text'])\n",
        "  print(row['sentiment'])\n",
        "  print_format()"
      ],
      "metadata": {
        "id": "9YswX79hmIB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise\n",
        "\n",
        "Apply the approach above to the `df_nyt` dataset."
      ],
      "metadata": {
        "id": "HWRk5HQx3ef_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Notice that it's a bit more complicated because the documents are longer than what the model takes\n",
        "# You need to make a decision about how to deal with that\n",
        "# Here I'm tokenizing at the sentence level and then calculating the sentiment of each sentence\n",
        "# You could go about it differently\n",
        "\n",
        "def calculate_sentiment_scores(sentences, sentiment_pipeline):\n",
        "    \"\"\"\n",
        "    Calculates sentiment scores for a list of sentences using a sentiment analysis pipeline.\n",
        "\n",
        "    Args:\n",
        "        sentences (list): A list of text strings to analyze.\n",
        "        sentiment_pipeline (callable): A sentiment analysis function or pipeline that accepts a sentence and returns a list of dictionaries with 'label' and 'score'.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of sentiment analysis results for each sentence.\n",
        "    \"\"\"\n",
        "    # Apply the sentiment pipeline to each sentence and collect results in a list\n",
        "    sentiment_scores = [sentiment_pipeline(sentence) for sentence in sentences]\n",
        "    return sentiment_scores\n",
        "\n",
        "\n",
        "def categorize_scores(input_list):\n",
        "    \"\"\"\n",
        "    Categorizes sentiment scores into POSITIVE and NEGATIVE buckets.\n",
        "\n",
        "    Args:\n",
        "        input_list (list): List of sentiment analysis results, each expected to be a list with one dictionary.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary with two keys 'POSITIVE' and 'NEGATIVE', each containing a list of scores.\n",
        "    \"\"\"\n",
        "    result = {'POSITIVE': [], 'NEGATIVE': []}  # Initialize result dictionary with empty lists\n",
        "    for item in input_list:\n",
        "        label = item[0]['label']  # Extract the sentiment label ('POSITIVE' or 'NEGATIVE')\n",
        "        score = item[0]['score']  # Extract the associated confidence score\n",
        "        if label == 'POSITIVE':\n",
        "            result['POSITIVE'].append(score)  # Append score to 'POSITIVE' list\n",
        "        elif label == 'NEGATIVE':\n",
        "            result['NEGATIVE'].append(score)  # Append score to 'NEGATIVE' list\n",
        "    return result\n",
        "\n",
        "\n",
        "def key_with_more_elements(input_dict):\n",
        "    \"\"\"\n",
        "    Identifies the key in a dictionary that has more elements in its value list.\n",
        "\n",
        "    Args:\n",
        "        input_dict (dict): Dictionary where values are lists.\n",
        "\n",
        "    Returns:\n",
        "        str: Key with the most elements.\n",
        "    \"\"\"\n",
        "    # Use max with key function to find the key with the longest list\n",
        "    return max(input_dict, key=lambda k: len(input_dict[k]))\n",
        "\n",
        "\n",
        "def key_with_highest_average(scores_dict):\n",
        "    \"\"\"\n",
        "    Finds the key with the highest average score in a dictionary of lists.\n",
        "\n",
        "    Args:\n",
        "        scores_dict (dict): Dictionary with keys 'POSITIVE' and 'NEGATIVE' and list of scores as values.\n",
        "\n",
        "    Returns:\n",
        "        str: Key with the highest average score.\n",
        "    \"\"\"\n",
        "    max_avg = float('-inf')  # Initialize max average with the lowest possible float\n",
        "    best_key = None  # Initialize variable to store the best key\n",
        "\n",
        "    for key, scores in scores_dict.items():\n",
        "        avg_score = sum(scores) / len(scores)  # Compute average score for each sentiment\n",
        "        if avg_score > max_avg:\n",
        "            max_avg = avg_score  # Update max average\n",
        "            best_key = key  # Update key with highest average\n",
        "\n",
        "    return best_key\n",
        "\n",
        "\n",
        "def calculate_sentiment_more_common(sentences, sentiment_pipeline):\n",
        "    \"\"\"\n",
        "    Determines the more common sentiment (POSITIVE or NEGATIVE) based on number of occurrences.\n",
        "\n",
        "    Args:\n",
        "        sentences (list): List of text sentences.\n",
        "        sentiment_pipeline (callable): A sentiment analysis function or pipeline that accepts a sentence and returns a list of dictionaries with 'label' and 'score'.\n",
        "\n",
        "    Returns:\n",
        "        str: Sentiment label with more occurrences.\n",
        "    \"\"\"\n",
        "    sentiment_scores = calculate_sentiment_scores(sentences, sentiment_pipeline)  # Get sentiment scores for all sentences\n",
        "    scores_dict = categorize_scores(sentiment_scores)  # Categorize scores into POSITIVE and NEGATIVE\n",
        "    sentiment = key_with_more_elements(scores_dict)  # Identify which sentiment appears more frequently\n",
        "    return sentiment\n",
        "\n",
        "\n",
        "def calculate_sentiment_higher_average(sentences, sentiment_pipeline):\n",
        "    \"\"\"\n",
        "    Determines the sentiment with the highest average confidence score.\n",
        "\n",
        "    Args:\n",
        "        sentences (list): List of text sentences.\n",
        "        sentiment_pipeline (callable): A sentiment analysis function or pipeline that accepts a sentence and returns a list of dictionaries with 'label' and 'score'.\n",
        "\n",
        "    Returns:\n",
        "        str: Sentiment label with the highest average score.\n",
        "    \"\"\"\n",
        "    sentiment_scores = calculate_sentiment_scores(sentences, sentiment_pipeline)  # Get sentiment scores for all sentences\n",
        "    scores_dict = categorize_scores(sentiment_scores)  # Categorize scores into POSITIVE and NEGATIVE\n",
        "    sentiment = key_with_highest_average(scores_dict)  # Find sentiment with the highest average score\n",
        "    return sentiment\n",
        "\n",
        "sentences = df_nyt_subset['sentences'].to_list()[0][:5]\n",
        "print(sentences)\n",
        "print(calculate_sentiment_more_common(sentences, sentiment_pipeline))\n",
        "print(calculate_sentiment_higher_average(sentences, sentiment_pipeline))"
      ],
      "metadata": {
        "id": "xj8pY59GTPdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how we get different answers depending on the way to aggregate. These are all choices that you have to think about and decide based on the context of your research."
      ],
      "metadata": {
        "id": "dkrKWI02WrRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Take even smaller subset for speed\n",
        "df_nyt_sub_subset = df_nyt.sample(5, random_state=51425)\n",
        "\n",
        "# Apply calculate_sentiment_more_common to dataset\n",
        "df_nyt_sub_subset['sentiment'] = df_nyt_sub_subset['sentences'].apply(lambda x: calculate_sentiment_more_common(x, sentiment_pipeline))"
      ],
      "metadata": {
        "id": "CoPqKSqVV0sI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, row in df_nyt_sub_subset.iterrows():\n",
        "  print(row['text'])\n",
        "  print(row['sentiment'])\n",
        "  print_format()"
      ],
      "metadata": {
        "id": "U9wfzt3aV_Eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using a decoder model\n",
        "\n",
        "Definition: using a decoder model (such as the one behind ChatGPT, which goes from text to text) to get sentiment labels.<br>\n",
        "Pros: easy to implement, flexible, good language understanding.<br>\n",
        "Cons: opaque, computationally intensive, not optimized for the task, you may have to pay, can be biased.<br>\n",
        "Use cases: many of the same use cases than dictionary-based sentiment analysis, particularly if there is not a good dictionary or pre-trained model for your task.<br>\n",
        "\n",
        "For [more information about encoder vs. decoder models, you can consult this workshop](https://github.com/nuitrcs/CoDEx-Choose-Your-LLM), which also provides advice on how to choose an LLM for your research project.\n",
        "\n",
        "For this notebook, we'll use the [OpenAI API](https://platform.openai.com/docs/overview). (You can see the [billing here](https://platform.openai.com/settings/organization/billing/overview), [get API keys here](https://platform.openai.com/api-keys), and [check your usage here](https://platform.openai.com/settings/organization/usage).) You can find open-source decoder models in [Hugging Face](https://huggingface.co/models) and [Ollama](https://ollama.com/library), both of which you can use locally or on [Quest](https://www.it.northwestern.edu/departments/it-services-support/research/computing/quest/).\n",
        "\n",
        "**Keep in mind that you may not be able to use APIs (such as OpenAI's) or even open-source models on Quest depending on the privacy and security level of your data. Please consult [Northwestern's Guidance on the Use of Generative AI](https://www.it.northwestern.edu/about/policies/guidance-on-the-use-of-generative-ai.html) and feel free to [submit a consult request with Research Computing and Data Services](https://app.smartsheet.com/b/form/2f2ec327e6164f83b588b7bbe2e2b56f) if you have any questions.**"
      ],
      "metadata": {
        "id": "xzVz1bD6Wb1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set API key as environmental variable\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Initialize the OpenAI client\n",
        "client = OpenAI()\n",
        "\n",
        "# Define a Pydantic model for sentiment analysis response\n",
        "# https://platform.openai.com/docs/guides/structured-outputs\n",
        "class SentimentResponse(BaseModel):\n",
        "    # The 'sentiment' field must be one of the specified literal values\n",
        "    sentiment: Literal[\"positive\", \"negative\", \"neutral\", \"unsure\"]\n",
        "\n",
        "# Define function to classify the sentiment\n",
        "def classify_sentiment(text):\n",
        "    \"\"\"\n",
        "    Classify the sentiment of the given text as positive, negative, neutral, or unsure.\n",
        "\n",
        "    Input:\n",
        "        text (str): A string containing the text to analyze for sentiment.\n",
        "\n",
        "    Output:\n",
        "        str: One of \"positive\", \"negative\", \"neutral\", or \"unsure\", representing the sentiment of the input text.\n",
        "    \"\"\"\n",
        "    # Call the OpenAI API using the structured output parsing interface\n",
        "    response = client.beta.chat.completions.parse(\n",
        "        model=\"gpt-4o\",  # Use the GPT-4o model for generating the response\n",
        "        messages=[\n",
        "            # Provide system instructions to guide the assistant's behavior\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a sentiment analysis assistant. Classify the sentiment of the provided text as positive, negative, neutral, or unsure.\"\n",
        "            },\n",
        "            # Include the user-provided text as input for classification\n",
        "            {\"role\": \"user\", \"content\": text},\n",
        "        ],\n",
        "        response_format=SentimentResponse  # Use the SentimentResponse schema to enforce structured output\n",
        "    )\n",
        "\n",
        "    # Return the sentiment value parsed from the structured response\n",
        "    return response.choices[0].message.parsed.sentiment"
      ],
      "metadata": {
        "id": "BR0B3CotWdjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_tweet = df_tweets['text'].to_list()[10]\n",
        "print(example_tweet)\n",
        "# print(classify_sentiment(example_tweet)) # Commenting to avoid keep sending requests"
      ],
      "metadata": {
        "id": "_yMJFwYesMoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise\n",
        "\n",
        "Use the inference widget for [DeepSeek-R1](https://huggingface.co/deepseek-ai/DeepSeek-R1), [HuggingChat](https://huggingface.co/chat/), and/or [ChatGPT](https://chatgpt.com/) to copy and paste some of the documents from `df_nyt` and get the sentiment. Compare the output that you get with the output of some of the previous approaches to sentiment analysis.\n",
        "\n",
        "### Training a classifier from scratch\n",
        "\n",
        "Definition: supervised learning model trained to classify documents.<br>\n",
        "Pros: can perform better than off-the-shelf approaches, tailored to the specific task, can be transparent.<br>\n",
        "Cons: requires more work, requires labeled data, can require feature engineering, can be opaque, can be computationally intensive.<br>\n",
        "Use cases: easier-to-implement approaches don't work, core analysis, you have a fair amount of labeled data, you want to label a fair amount of documents or the model will become part of a pipeline for your lab/future work.<br>\n",
        "\n",
        "You can find [more information about training a classifier from scratch in this workshop](https://github.com/nuitrcs/scikit-learn-workshop). You can also attend [Research Computing and Data Services' Scikit-Learn workshop this summer](https://www.it.northwestern.edu/departments/it-services-support/research/training-and-consultation/research-code-academy.html). [This free book](https://www.statlearning.com/) is also a good place to learn more about supervised learning.\n",
        "<br>\n",
        "<br>\n",
        "Remember that in `df_tweets` we created a column called `sentiment` using the VADER dictionary:"
      ],
      "metadata": {
        "id": "oK-fObBnWPI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tweets['sentiment'].value_counts()"
      ],
      "metadata": {
        "id": "jIouMVoiGLzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the sake of this notebook, we're going to use that column as our label to create a classifier from scratch. **Of course, in real life research it wouldn't make sense to do that. You'd want to have ground truth data to train a classifier from scratch, most likely a set of manually labeled data.**"
      ],
      "metadata": {
        "id": "j9D3ajBYJXwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df_tweets['text'],\n",
        "    df_tweets['sentiment'],\n",
        "    test_size=0.2, # 80% train, 20% test\n",
        "    random_state=51425\n",
        ")"
      ],
      "metadata": {
        "id": "NO9Gqs56LXE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "mDFVjaV_LghH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "id": "m1sRBhviLY96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "2iagb9T4Li9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.head()"
      ],
      "metadata": {
        "id": "vF_i_nYuLY6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "id": "LEry61mwLY1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.head()"
      ],
      "metadata": {
        "id": "Meve9GZ8LYsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "id": "iWknOGs2LpQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.head()"
      ],
      "metadata": {
        "id": "EpI29xdTLrwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a pipeline with:\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
        "# https://github.com/nuitrcs/sklearn_pipelines\n",
        "# 1. TfidfVectorizer: converts text into numerical features using TF-IDF\n",
        "# https://en.wikipedia.org/wiki/Document-term_matrix\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
        "# https://www.geeksforgeeks.org/understanding-tf-idf-term-frequency-inverse-document-frequency/\n",
        "#    - ngram_range=(1,1): unigrams only\n",
        "#    - max_features=3000: limit vocabulary to top 1000 terms\n",
        "# 2. MultinomialNB: Naive Bayes classifier suited for word count features\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
        "# \"The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work.\"\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(ngram_range=(1, 1), max_features=1000)),\n",
        "    ('nb', MultinomialNB())\n",
        "])\n",
        "\n",
        "pipeline"
      ],
      "metadata": {
        "id": "SqKJz0WOLxzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the pipeline\n",
        "pipeline.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "_VPHtt2-LxpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test set\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "y_pred[:10]"
      ],
      "metadata": {
        "id": "HLsCi9PWL5UE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "NglcYOLnLJi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise\n",
        "\n",
        "Apply the approach above on the same dataset, but using a support vector machine and/or logistic regression instead of multinomial naive bayes."
      ],
      "metadata": {
        "id": "FsX4r6703k-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(ngram_range=(1, 1), max_features=1000)),\n",
        "    # https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\n",
        "    # \"LinearSVC is another (faster) implementation of Support Vector Classification for the case of a linear kernel.\"\n",
        "    ('svm', LinearSVC())\n",
        "])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "5IvHkNF7GMWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(ngram_range=(1, 1), max_features=1000)),\n",
        "    # https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "    ('logreg', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "f9Z9RlNDNstt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-tuning a language model\n",
        "\n",
        "Definition: using a pre-trained language model and tailoring it to your specific task.<br>\n",
        "Pros: takes advantage of the knowledge of pre-trained models, can work really well.<br>\n",
        "Cons: opaque, computationally intensive, requires labeled data, can be biased.<br>\n",
        "Use cases: similar use cases than for training a classifier from scratch, typically with less data required.<br>\n",
        "\n",
        "You can find open-source language models to fine-tune in [Hugging Face](https://huggingface.co/models).\n",
        "\n",
        "Given time constraints, this notebook cannot cover fine-tuning. However, you can always [submit a consult request with Research Computing and Data Services](https://app.smartsheet.com/b/form/2f2ec327e6164f83b588b7bbe2e2b56f) if you need help with the data-related aspects of your research and attend [Research Computing and Data Services' fine-tuning workshop this summer](https://www.it.northwestern.edu/departments/it-services-support/research/training-and-consultation/research-code-academy.html).\n",
        "\n",
        "#### Exercise\n",
        "\n",
        "This notebook covered various approaches to sentiment analysis, particularly dictionaries or lexicons, pre-trained classifiers, using decoders, fine-tuning a language model, and training a model from scratch.\n",
        "\n",
        "What approach(es) to sentiment analysis (if at all) would you use for each of these research projects?\n",
        "\n",
        "1. A marketing scholar is studying sentiment in Amazon product reviews to compare customer satisfaction between sustainable and non-sustainable products. There are 10,000 labeled reviews.<br>\n",
        "2. A health researcher has collected open-ended responses from 300 patients about their hospital experience. They want to summarize the overall sentiment to identify major areas of concern.<br>\n",
        "3. A legal scholar is analyzing judicial opinions to see if courts have become more negative in tone toward environmental regulations over time. They have 1,000 documents and no labeled data.<br>\n",
        "4. A sociologist is studying public reaction to a major protest movement using tweets. They have 50,000 tweets collected during a two-week period.<br>\n",
        "5. A political scientist is analyzing how candidates express sentiment about the economy during campaign speeches. They want to track differences between parties and over time.<br>\n",
        "6. A historian is analyzing personal letters written during the Great Depression to understand emotional tone. The data are unstructured and old-fashioned in language.<br>\n",
        "\n",
        "## Conclusions and next steps to continue learning\n",
        "\n",
        "This notebook covered various approaches to sentiment analysis, particularly dictionaries or lexicons, pre-trained classifiers, using decoders, fine-tuning a language model, and training a model from scratch. **Keep in mind that you can potentially use approaches in combination.**\n",
        "\n",
        "The notebook also provided resources and code that you can use to continue learning about the different approaches and find out the one that works best for your project.\n",
        "\n",
        "**Keep in mind that, while not elaborated on this notebook, evaluating your approach is critical.**\n",
        "\n",
        "You are always welcome to [submit a consult request with Research Computing and Data Services](https://app.smartsheet.com/b/form/2f2ec327e6164f83b588b7bbe2e2b56f) if you need help with the data-related aspects of your research.\n",
        "\n",
        "This notebook is partly based on these three articles, where you can read more in-depth and find other references:\n",
        "- Stine, R.A. (2019). Sentiment Analysis.*Annual Review of Statistics and Its Applications*, 6, 287-308. (Available [here](https://doi.org/10.1146/annurev-statistics-030718-105242).)\n",
        "- Bestvater, S.E. & Monroe, B.L. (2023). Sentiment is Not Stance: Target-Aware Opinion Classification for Political Text Analysis. *Political Analysis*, 31, 235-256. (Available [here](https://doi.org/10.1017/pan.2022.10).)\n",
        "- Wankm√ºller, S. (2024). Introduction to Neural Transfer Learning With Transformers for Social Science Text Analysis. *Sociological Methods & Research*, 53(4), 1676-1752. (Available [here](https://doi.org/10.1177/00491241221134527).)\n",
        "\n",
        "This notebook uses code produced by ChatGPT. That's okay to do as long as you consider the privacy, security, and intellectual property implications, as well as understand the code. We do have a [workshop on writing effective prompts for coding with LLMs](https://github.com/nuitrcs/promptEngineering)."
      ],
      "metadata": {
        "id": "rmoVhsBkWSwK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fz-t85WQGuPU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}